Folder Structure in S3:

s3://your-bucket-name/
‚îÇ
‚îú‚îÄ‚îÄ incoming/       ‚Üê Upload .txt files here
‚îú‚îÄ‚îÄ encrypted/      ‚Üê Encrypted .pgp files saved here
‚îî‚îÄ‚îÄ archived/       ‚Üê Original .txt files moved here (or deleted)

Lambda Workflow (On .txt Upload to incoming/):
Triggered by .txt file upload to incoming/

Fetch PGP public key from Secrets Manager
Encrypt file using PGP
Save encrypted .pgp to encrypted/
Move original .txt to archived/ or delete it

Assumptions
PGP public key is stored in AWS Secrets Manager under a secret name like PGP_PUBLIC_KEY.
You're using Python for the Lambda.
Lambda has appropriate IAM permissions (S3, SecretsManager, etc.).

Full Lambda Code Example (Python)

import boto3
import gnupg
import os

s3 = boto3.client('s3')
secrets = boto3.client('secretsmanager')

gpg = gnupg.GPG(gnupghome='/tmp/.gnupg')

def lambda_handler(event, context):
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']

    if not key.startswith('incoming/') or not key.endswith('.txt'):
        return {'statusCode': 200, 'body': 'Not a target .txt file'}

    filename = os.path.basename(key)
    local_txt_path = f'/tmp/{filename}'
    encrypted_path = f'/tmp/{filename}.pgp'

    # Get the PGP public key from AWS Secrets Manager
    secret_response = secrets.get_secret_value(SecretId='PGP_PUBLIC_KEY')
    public_key = secret_response['SecretString']
    gpg.import_keys(public_key)

    # Download file from S3
    s3.download_file(bucket, key, local_txt_path)

    # Encrypt the file
    with open(local_txt_path, 'rb') as f:
        gpg.encrypt_file(f, output=encrypted_path, recipients=None, always_trust=True)

    # Upload encrypted file to 'encrypted/' folder
    s3.upload_file(encrypted_path, bucket, f'encrypted/{filename}.pgp')

    # Optional: move original to 'archived/' folder (or delete)
    s3.copy_object(
        Bucket=bucket,
        CopySource={'Bucket': bucket, 'Key': key},
        Key=f'archived/{filename}'
    )
    s3.delete_object(Bucket=bucket, Key=key)

    return {'statusCode': 200, 'body': f'{key} encrypted and moved successfully.'}
IAM Permissions Needed
Attach these permissions to your Lambda execution role:


{
  "Effect": "Allow",
  "Action": [
    "s3:GetObject",
    "s3:PutObject",
    "s3:DeleteObject",
    "s3:CopyObject",
    "secretsmanager:GetSecretValue"
  ],
  "Resource": "*"
}
(Refine Resource to be bucket-specific for production)

Storing the Public Key in AWS Secrets Manager

aws secretsmanager create-secret \
  --name PGP_PUBLIC_KEY \
  --secret-string file://public-key.asc
Or paste the armored key directly in the Secrets Manager UI.

==============================
==============================
===============================
Example Setup
üî∏ S3 Bucket Name
your-company-data-bucket

üî∏ File Upload Example
You upload:
incoming/client-report-2025-07-01.txt

Full S3 path:
s3://your-company-data-bucket/incoming/client-report-2025-07-01.txt
üîÅ Result After Lambda Processing
üîπ Encrypted File:
s3://your-company-data-bucket/encrypted/client-report-2025-07-01.txt.pgp

üîπ Original File Archived:
s3://your-company-data-bucket/archived/client-report-2025-07-01.txt

üß† Full Lambda Example With These Paths

import boto3
import gnupg
import os

s3 = boto3.client('s3')
secrets = boto3.client('secretsmanager')

gpg = gnupg.GPG(gnupghome='/tmp/.gnupg')

def lambda_handler(event, context):
    # Example event
    # s3://your-company-data-bucket/incoming/client-report-2025-07-01.txt

    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']

    if not key.startswith('incoming/') or not key.endswith('.txt'):
        return {'statusCode': 200, 'body': 'Not a valid .txt file in incoming/'}

    filename = os.path.basename(key)
    local_txt_path = f'/tmp/{filename}'
    encrypted_path = f'/tmp/{filename}.pgp'

    # üîê Load PGP public key from Secrets Manager
    secret_response = secrets.get_secret_value(SecretId='PGP_PUBLIC_KEY')
    public_key = secret_response['SecretString']
    gpg.import_keys(public_key)

    # üì• Download file from S3
    s3.download_file(bucket, key, local_txt_path)

    # üîê Encrypt file using PGP
    with open(local_txt_path, 'rb') as f:
        gpg.encrypt_file(f, output=encrypted_path, recipients=None, always_trust=True)

    # üì§ Upload encrypted file
    encrypted_s3_key = f'encrypted/{filename}.pgp'
    s3.upload_file(encrypted_path, bucket, encrypted_s3_key)

    # üóÇÔ∏è Archive original file
    archived_s3_key = f'archived/{filename}'
    s3.copy_object(
        Bucket=bucket,
        CopySource={'Bucket': bucket, 'Key': key},
        Key=archived_s3_key
    )
    s3.delete_object(Bucket=bucket, Key=key)

    return {
        'statusCode': 200,
        'body': f'File encrypted to {encrypted_s3_key} and moved to {archived_s3_key}'
    }
Upload Simulation
To test this:


aws s3 cp client-report-2025-07-01.txt s3://your-company-data-bucket/incoming/
If everything is configured correctly, Lambda will:

Encrypt it

Save to: s3://your-company-data-bucket/encrypted/client-report-2025-07-01.txt.pgp

Move original to: s3://your-company-data-bucket/archived/client-report-2025-07-01.txt
